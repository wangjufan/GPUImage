{\rtf1\ansi\ansicpg936\cocoartf1561\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset134 PingFangSC-Regular;\f2\fnil\fcharset0 Consolas;
}
{\colortbl;\red255\green255\blue255;\red255\green255\blue255;\red60\green60\blue60;\red83\green83\blue83;
\red0\green0\blue0;\red49\green49\blue49;\red114\green46\blue164;\red15\green125\blue210;\red245\green245\blue245;
\red20\green20\blue20;\red26\green26\blue26;\red239\green239\blue239;\red71\green71\blue71;\red191\green191\blue191;
\red253\green153\blue50;\red109\green109\blue109;}
{\*\expandedcolortbl;;\cssrgb\c100000\c100000\c100000;\cssrgb\c30196\c30196\c30196;\cssrgb\c40000\c40000\c40000;
\cssrgb\c0\c0\c0;\cssrgb\c25098\c25098\c25098;\cssrgb\c52549\c27843\c70196;\cssrgb\c0\c57255\c85882;\cssrgb\c96863\c96863\c96863;
\cssrgb\c10196\c10196\c10196;\cssrgb\c13333\c13333\c13333;\cssrgb\c94902\c94902\c94902;\cssrgb\c34902\c34902\c34902;\csgray\c79525;
\cssrgb\c100000\c66275\c25098;\cssrgb\c50196\c50196\c50196;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}.}{\leveltext\leveltemplateid1\'01.;}{\levelnumbers;}\fi-360\li720\lin720 }{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}.}{\leveltext\leveltemplateid2\'01.;}{\levelnumbers;}\fi-360\li1440\lin1440 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid101\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid201\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid301\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid401\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid501\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid601\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid701\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{none\}}{\leveltext\leveltemplateid801\'00;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid9}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}}
\margl1440\margr1440\vieww9000\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\li600\fi-14\ri-9798\sl560\partightenfactor0

\f0\fs48 \cf2 \expnd0\expndtw0\kerning0
\

\itap1\trowd \taflags0 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalc \clshdrawnil \clwWidth2540\clftsWidth3 \clmart10 \clmarl10 \clmarb10 \clmarr10 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl480 \clpadr0 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl400\partightenfactor0

\b\fs33\fsmilli16667 \cf3 \cell \lastrow\row
\pard\pardeftab720\li600\fi-14\ri-9798\sl380\partightenfactor0
\ls1\ilvl0
\b0 \cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#what-is-a-shader"}}{\fldrslt \expnd0\expndtw0\kerning0
What Is a Shader?}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#our-first-shader-example"}}{\fldrslt \expnd0\expndtw0\kerning0
Our First Shader Example}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl340\partightenfactor0
\ls1\ilvl1
\fs30 \cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#the-vertex-shader"}}{\fldrslt \expnd0\expndtw0\kerning0
The Vertex Shader}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 
\fs33\fsmilli16667 \cf5 \
\ls1\ilvl1
\fs30 \cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#the-fragment-shader"}}{\fldrslt \expnd0\expndtw0\kerning0
The Fragment Shader}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 
\fs33\fsmilli16667 \cf5 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl380\partightenfactor0
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#glsl-data-types-and-operations"}}{\fldrslt \expnd0\expndtw0\kerning0
GLSL Data Types and Operations}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#inputs-outputs-and-precision-qualifiers"}}{\fldrslt \expnd0\expndtw0\kerning0
Inputs, Outputs, and Precision Qualifiers}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#vectors"}}{\fldrslt \expnd0\expndtw0\kerning0
Vectors}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#matrices"}}{\fldrslt \expnd0\expndtw0\kerning0
Matrices}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#vector-and-matrix-operations-aka-linear-algebra-101"}}{\fldrslt \expnd0\expndtw0\kerning0
Vector and Matrix Operations, AKA Linear Algebra 101}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#glsl-specific-functions"}}{\fldrslt \expnd0\expndtw0\kerning0
GLSL-Specific Functions}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#more-complex-shader-examples"}}{\fldrslt \expnd0\expndtw0\kerning0
More Complex Shader Examples}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl340\partightenfactor0
\ls1\ilvl1
\fs30 \cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#saturation-adjustment"}}{\fldrslt \expnd0\expndtw0\kerning0
Saturation Adjustment}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 
\fs33\fsmilli16667 \cf5 \
\ls1\ilvl1
\fs30 \cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#sphere-refraction"}}{\fldrslt \expnd0\expndtw0\kerning0
Sphere Refraction}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 
\fs33\fsmilli16667 \cf5 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl380\partightenfactor0
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#debugging-shaders"}}{\fldrslt \expnd0\expndtw0\kerning0
Debugging Shaders}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#performance-tuning"}}{\fldrslt \expnd0\expndtw0\kerning0
Performance Tuning}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\ls1\ilvl0\cf4 \cb2 \kerning1\expnd0\expndtw0 {\listtext	.	}{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-image-processing/#conclusions-and-resources"}}{\fldrslt \expnd0\expndtw0\kerning0
Conclusions and Resources}}\cb1 \expnd0\expndtw0\kerning0
\uc0\u8232 \cf5 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\fs40 \cf6 Instagram. Snapchat. Photoshop.\
		All of these applications are used to do image processing. Image processing can be as simple as converting a photo to grayscale and as complex as analyzing a video of a crowd for a specific person. In spite of how divergent these applications are, both of these examples go through the same process from creation to rendering.\
		There are many ways to process images on your computer or mobile phone, but by far the most efficient is effectively using your Graphics Processing Unit, or GPU
\f1 \'b3\'e4\'b7\'d6\'c0\'fb\'d3\'c3
\f0 GPU
\f1 \'b4\'a6\'c0\'ed\'b5\'a5\'d4\'aa\'ca\'c7\'d7\'ee\'d3\'d0\'d0\'a7\'b5\'c4\'cd\'bb\'c6\'c6\'b4\'a6\'c0\'ed\'b7\'bd\'ca\'bd
\f0 . Your phone contains two different processing units, the CPU and the GPU. The CPU is a generalist that has to deal with everything, while your GPU can focus on doing one thing really well, which is doing floating-point math in parallel
\f1 \'b2\'a2\'d0\'d0\'b8\'a1\'b5\'e3\'d4\'cb\'cb\'e3
\f0 ; it turns out that image processing and rendering 
\f1 \'cd\'bc\'c6\'ac\'b4\'a6\'c0\'ed\'d3\'eb\'e4\'d6\'c8\'be
\f0 is nothing more than 
\f1 \'d7\'f6\'ba\'dc\'b6\'e0\'b8\'a1\'b5\'e3\'ca\'fd\'d1\'a7
\f0 doing a lot of floating-point math on the values for the pixels that render to your screen
\f1 \'e4\'d6\'c8\'be\'b5\'bd\'c6\'c1\'c4\'bb\'c9\'cf\'b5\'c4\'cf\'f1\'cb\'d8\'d6\'b5
\f0 .\
		By effectively utilizing your GPU, you can increase graphics-rendering performance on your phone by a hundred fold
\f1 \'d3\'d0\'d0\'a7\'ca\'b9\'d3\'c3
\f0 GPU
\f1 \'bf\'c9\'d2\'d4\'d6\'c1\'c9\'d9\'cc\'e1\'c9\'fd\'bc\'b8\'b0\'d9\'b1\'b6\'b5\'c4\'cd\'bc\'cf\'f1\'b4\'a6\'c0\'ed\'d0\'d4\'c4\'dc
\f0 , if not a thousand fold. Being able to filter high-quality live video on your phone is impractical or even impossible without GPU-based processing.
\f1 \'b2\'bb\'ca\'b9\'d3\'c3\'bb\'f9\'d3\'da
\f0 GPU
\f1 \'b5\'c4\'b4\'a6\'c0\'ed\'a3\'ac\'b9\'fd\'c2\'cb\'b8\'df\'d6\'ca\'c1\'bf\'ca\'d3\'c6\'b5\'a3\'ac\'ca\'c7\'b2\'bb\'bf\'c9\'c4\'dc\'d3\'eb\'b2\'bb\'cf\'d6\'ca\'b5\'b5\'c4\'a1\'a3
\f0 \
		The tool we use to take advantage of this power is a shader
\f1 \'ca\'b9\'d3\'c3\'d7\'c5\'c9\'ab\'c6\'f7\'c0\'b4\'b3\'e4\'b7\'d6\'b7\'a2\'bb\'d3\'d5\'e2\'cf\'ee\'d3\'c5\'ca\'c6
\f0 . A shader is a small, C-based program written in a shading language
\f1 \'d2\'bb\'b8\'f6\'d7\'c5\'c9\'ab\'c6\'f7\'a3\'ac\'ca\'c7\'d3\'c3\'d7\'c5\'c9\'ab\'d3\'ef\'d1\'d4\'b1\'e0\'d0\'b4\'b5\'c4\'a3\'ac\'d2\'bb\'b8\'f6\'d0\'a1\'b5\'c4\'a1\'a2\'bb\'f9\'d3\'daC\'d3\'ef\'d1\'d4\'b5\'c4\'b3\'cc\'d0\'f2
\f0 . There are many shading languages out there on the market, but the one you should focus on if you are doing OS X or iOS development is the -----OpenGL Shading Language, or GLSL. You can take the concepts from GLSL and apply them to other, more proprietary languages like the -----Metal Shading Language. The concepts we are going over here even map well to ----custom kernels in Core Image, although they use a slightly different syntax.\
		This process can be incredibly daunting, especially to newer developers. The purpose of this article is to get your feet wet with some foundation information necessary to get you going on your journey to writing your own image processing shaders
\f1 \'d0\'b4\'d7\'d4\'bc\'ba\'b5\'c4\'cd\'bc\'c6\'ac\'b4\'a6\'c0\'ed\'d7\'c5\'c9\'ab\'c6\'f7
\f0 .\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 What Is a Shader?\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		We\'92re going to take a short trip in The Wayback Machine to get an overview of what a shader is and how it came to be an integral part of our workflow.
\f1 \'ca\'b2\'c3\'b4\'ca\'c7\'d7\'c5\'c9\'ab\'c6\'f7\'a3\'ac\'cb\'fc\'ca\'c7\'c8\'e7\'ba\'ce\'b3\'c9\'ce\'aa\'b9\'a4\'d7\'f7\'c1\'f7\'b5\'c4\'d2\'bb\'b2\'bf\'b7\'d6
\f0 \
		If you\'92ve been doing iOS programming since at least iOS 5, you might be aware that there was a shift in OpenGL programming on the iPhone, from OpenGL ES 1.1 to OpenGL ES 2.0.\
		OpenGL ES 1.1 did not use shaders \'97 it used what is called a fixed-function pipeline
\f1 \'b9\'cc\'b6\'a8\'ba\'af\'ca\'fd\'b9\'dc\'cf\'df
\f0 . Instead of creating a separate program to direct the operation of the GPU
\f1 \'ca\'b9\'d3\'c3\'b6\'c0\'c1\'a2\'b5\'c4\'b3\'cc\'d0\'f2\'d6\'b8\'b5\'bc
\f0 GPU, there was a set of fixed functions that you used to render objects on the screen
\f1 \'ca\'b9\'d3\'c3\'d2\'bb\'d7\'e9\'b9\'cc\'b6\'a8\'ba\'af\'ca\'fd\'a3\'ac\'b0\'d1\'b6\'d4\'cf\'f3\'e4\'d6\'c8\'be\'b5\'bd\'c6\'c1\'c4\'bb\'c9\'cf
\f0 . This was incredibly limiting, and you weren\'92t able to get any specialized effects. If you want a good example of how much of a difference shaders can make in a project,\'a0{\field{\*\fldinst{HYPERLINK "http://www.sunsetlakesoftware.com/2011/05/08/enhancing-molecules-using-opengl-es-20"}}{\fldrslt \cf7 check out this blog post Brad Larson wrote about refactoring his Molecules app using shaders instead of the fixed-function pipeline.}}\
		OpenGL ES 2.0 introduced the programmable pipeline
\f1 \'bf\'c9\'b1\'e0\'b3\'cc\'b9\'dc\'cf\'df
\f0 . The programmable pipeline allowed you to go in and write your own shaders
\f1 \'d0\'b4\'d7\'d4\'bc\'ba\'b5\'c4\'d7\'c5\'c9\'ab\'c6\'f7
\f0 , giving you far more power and flexibility
\f1 \'b8\'fc\'b4\'f3\'b5\'c4\'c1\'e9\'bb\'ee\'d0\'d4\'d3\'eb\'c4\'dc\'c1\'a6
\f0 .\
		There are 
\f1 \'c1\'bd\'d6\'d6\'d7\'c5\'c9\'ab\'c6\'f7\'ce\'c4\'bc\'fe
\f0  two kinds of shader files that you must create in OpenGL ES: vertex shaders and fragment shaders
\f1 \'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7 \'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7
\f0 . These shaders are two halves of a whole program
\f1 \'cb\'fc\'c3\'c7\'ca\'c7\'d2\'bb\'b8\'f6\'cd\'ea\'d5\'fb\'b3\'cc\'d0\'f2\'b5\'c4\'c1\'bd\'b8\'f6\'b2\'bf\'b7\'d6\'a3\'ac\'c8\'b1\'d2\'bb\'b2\'bb\'bf\'c9
\f0 . You can\'92t just create one or the other; both must be present to comprise a whole shader program.\
		Vertex shaders customize how geometry is handled in a 2D or 3D scene
\f1 \'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7\'a3\'ac\'b6\'a8\'d2\'e5\'c8\'e7\'ba\'ce\'d4\'da2D\'bb\'f2\'ca\'c73D\'b3\'a1\'be\'b0\'d6\'d0\'c8\'e7\'ba\'ce\'b4\'a6\'c0\'ed\'bc\'b8\'ba\'ce\'ce\'ca\'cc\'e2
\f0 . A vertex is a point in 2D or 3D space. In the case of image processing, we have four vertices
\f1 \'d4\'da\'cd\'bc\'cf\'f1\'b4\'a6\'c0\'ed\'d6\'d0\'a3\'ac\'d3\'d0\'cb\'c4\'b8\'f6\'b6\'a5\'b5\'e3
\f0 : one for each corner of your image. The vertex shader 
\f1 \'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7\'c9\'e8\'d6\'c3\'b6\'a5\'b5\'e3\'b5\'c4\'ce\'bb\'d6\'c3
\f0 sets the position of a vertex and sends parameters like positions and texture coordinates to the fragment shader
\f1 \'b7\'a2\'cb\'cd\'ce\'bb\'d6\'c3\'d3\'eb\'ce\'c6\'c0\'ed\'d7\'f8\'b1\'ea\'b5\'c8\'b2\'ce\'ca\'fd\'b5\'bd\'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7
\f0 .\
		Your GPU then uses a fragment shader to perform calculations on each pixel in an object or image GPU
\f1 \'ca\'b9\'d3\'c3\'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7\'a3\'ac\'bc\'c6\'cb\'e3\'b6\'d4\'cf\'f3\'bb\'f2\'ca\'c7\'cd\'bc\'cf\'f1\'d6\'d0\'b5\'c4\'c3\'bf\'d2\'bb\'b8\'f6\'cf\'f1\'cb\'d8\'d6\'b5
\f0 , ending with the final color for that pixel
\f1 \'b5\'c3\'b5\'bd\'d7\'ee\'ba\'f3\'b5\'c4\'cf\'f1\'cb\'d8\'d1\'d5\'c9\'ab
\f0 . An image, when you get right down to it, is simply a collection of data. The image document contains parameters for the value of each pixel
\f1 \'cf\'f1\'cb\'d8\'d6\'b5
\f0 , for each color component
\f1 \'c3\'bf\'d2\'bb\'b8\'f6\'d1\'d5\'c9\'ab\'d7\'e9\'bc\'fe
\f0 , and for the pixel\'92s opacity
\f1 \'cf\'f1\'cb\'d8\'cd\'b8\'c3\'f7\'b6\'c8
\f0 . Because the equations are the same for each pixel, the GPU is able to streamline the process and do it more efficiently. If you are optimizing your shader properly, you can process image data on the GPU more than 100 times faster than if you were to run the same process on the CPU.
\f1 \'ca\'ca\'b5\'b1\'d3\'c5\'bb\'af\'b5\'c4\'d7\'c5\'c9\'ab\'c6\'f7\'a3\'ac\'ca\'b9\'d3\'c3
\f0 GPU
\f1 \'bb\'f1\'b5\'c3
\f0 100
\f1 \'b1\'b6\'cc\'e1\'cb\'d9\'a1\'a3
\f0 \
		One issue that has plagued OpenGL developers from the beginning is just being able to render anything on the screen. There is a lot of boilerplate code and setup that needs to be done in order to get a screen that isn\'92t black. The frustration and the inability to test out shaders because of all the hoops developers had to jump through in the past has discouraged a lot of people from even trying to get involved in writing shaders.\
		Fortunately, in the last few years, several tools and frameworks have been made available to take some of the anxiety out of trying out shaders:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl580\partightenfactor0
\ls2\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "https://github.com/BradLarson/GPUImage"}}{\fldrslt \expnd0\expndtw0\kerning0
GPUImage}}\cf6 \expnd0\expndtw0\kerning0
\
\ls2\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "https://www.shadertoy.com/"}}{\fldrslt \expnd0\expndtw0\kerning0
ShaderToy}}\cf6 \expnd0\expndtw0\kerning0
\
\ls2\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "http://www.shaderific.com/"}}{\fldrslt \expnd0\expndtw0\kerning0
Shaderific}}\cf6 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720\li600\fi-14\ri-9798\sl580\partightenfactor0
\ls2\ilvl0\cf6 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
Quartz Composer\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 		Each of the shader examples I am going through here comes from the open-source GPUImage framework. If you are more curious about how an OpenGL/OpenGL ES scene is configured to render using shaders, feel free to clone the repository. I will not be going into how to set up OpenGL/OpenGL ES to render using shaders like this, as it is beyond the scope of the article.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 Our First Shader Example\
\pard\pardeftab720\li600\fi-14\ri-9798\sl680\partightenfactor0

\fs57\fsmilli28800 \cf6 The Vertex Shader\

\f1 \'bc\'b8\'ba\'ce\'b5\'e3\'b1\'ed\'b4\'ef + \'b1\'ed\'cf\'f3\'b5\'e3\'b1\'ed\'b4\'ef + with \'c4\'da\'d6\'c3\'b1\'e4\'c1\'bf
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 Alright, enough talking about shaders. Let\'92s see an actual shader program in action. Here is the baseline vertex shader in GPUImage:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 attribute vec4 position; 
\f1 \'d7\'f8\'b1\'ea\'cf\'f2\'c1\'bf\'a3\'ac\'bb\'ad\'b2\'bc\'d6\'d0\'ce\'bb\'d6\'c3
\f2 \
attribute vec4 inputTextureCoordinate;\
\
varying vec2 textureCoordinate;\
\
void main()\
\{\
    gl_Position = position;\
    textureCoordinate = inputTextureCoordinate.xy;\
\}\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 Let\'92s take this piece by piece:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 attribute vec4 position;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		Like all languages, the designers of our shading language knew to create special data types for commonly used types,
\f1 \'ce\'aa\'cd\'a8\'b3\'a3\'ca\'b9\'d3\'c3\'b5\'c4\'c0\'e0\'d0\'cd\'a3\'ac\'b4\'b4\'d4\'ec\'cc\'d8\'ca\'e2\'b5\'c4\'ca\'fd\'be\'dd\'c0\'e0\'d0\'cd
\f0  such as 2D and 3D coordinates. These types are vectors
\f1 \'cf\'f2\'c1\'bf
\f0 , which we will go into more depth with a little later. Back in our application code, we are creating a list of vertices
\f1 \'b6\'a5\'b5\'e3\'c1\'d0\'b1\'ed
\f0 , and one of the parameters we provide per vertex is its position within our canvas
\f1 \'ce\'aa\'c3\'bf\'d2\'bb\'b8\'f6\'b6\'a5\'b5\'e3\'cc\'e1\'b9\'a9\'d4\'da\'bb\'ad\'b2\'bc\'d6\'d0\'b5\'c4\'ce\'bb\'d6\'c3
\f0 . We then have to tell our vertex shader that it needs to take that parameter and that we are going to use it for something. Since this is a C program, we need to remember to use a semicolon at the end of each line of code, so if you are coding in Swift you need to remember to pick the semicolon habit back up.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 attribute vec4 inputTextureCoordinate;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		At this point you might be wondering why we are getting a texture coordinate. Didn\'92t we just get our vertex position? Aren\'92t these the same thing?
\f1 \'ce\'c6\'c0\'ed\'d7\'f8\'b1\'ea\'a1\'a3\'b6\'a5\'b5\'e3\'d7\'f8\'b1\'ea  
\f0 \
		No, not necessarily. A texture coordinate is part of a texture map
\f1 \'ce\'c6\'c0\'ed\'d7\'f8\'b1\'ea\'a3\'ac\'ce\'c6\'c0\'ed\'d3\'b3\'c9\'e4\'b5\'c4\'d2\'bb\'b2\'bf\'b7\'d6
\f0 . What this means is that you have the image you want to filter, which is your texture. The upper left-hand corner has a coordinate space of (0, 0). The upper right-hand corner has a coordinate space of (1,0). If we wanted to select a texture coordinate that was inside the image and not at the edges, we would specify that the texture coordinate was something else in our base application, like (.25, .25), which would be located a quarter of the way in and down on our image
\f1 \'cb\'c4\'b7\'d6\'d6\'ae\'d2\'bb
\f0 . In our current image processing application, we want the texture coordinate and the vertex position to line up, because we want to cover the entire length and breadth of our image
\f1 \'cd\'bc\'c6\'ac\'b5\'c4\'d5\'fb\'b8\'f6\'b3\'a4\'b6\'c8\'d3\'eb\'bf\'ed\'b6\'c8
\f0 . There are times where you might want these positions to be different, so it\'92s important to remember that they don\'92t necessarily need to be the same coordinate. Also, the coordinate space for vertices in this example extends from \uc0\u8722 1.0 to 1.0, where texture coordinates go from 0.0 to 1.0.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 varying vec2 textureCoordinate;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		Since the vertex shader is responsible for communicating with the fragment shader
\f1 \'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7\'b8\'ba\'d4\'f0\'d3\'eb\'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7\'cd\'a8\'d0\'c5
\f0 , we need to create a variable that will share pertinent information with it. With image processing, the only piece of pertinent information it needs from the vertex shader is what pixel is it currently working on.
\f1 \'b5\'b1\'c7\'b0\'b1\'bb\'b4\'a6\'c0\'ed\'b5\'c4\'cf\'f1\'cb\'d8\'b5\'c4\'d7\'f8\'b1\'ea
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 gl_Position = position;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl540\partightenfactor0

\fs36 \cf11 \cb12 		gl_Position
\f0\fs40 \cf6 \cb1 \'a0is a built-in variable
\f1 \'c4\'da\'d6\'c3\'b1\'e4\'c1\'bf
\f0 . GLSL has a few built-in variables, one of which we will see in the fragment shader example. These are special variables 
\f1 \'cc\'d8\'ca\'e2\'b5\'c4\'b1\'e4\'c1\'bf
\f0 that are a part of the programmable pipeline
\f1 \'bf\'c9\'b1\'e0\'b3\'cc\'b9\'dc\'cf\'df\'b5\'c4\'d2\'bb\'b2\'bf\'b7\'d6
\f0  that the API knows to look for and knows how to associate. In this case, we are specifying the vertex position and feeding that from our base program to the render pipeline.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 textureCoordinate = inputTextureCoordinate.xy;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		Finally, we are extracting the X and Y positions of the texture coordinate at this vertex. The coordinate was initially fed into the vertex shader with four attributes, but we only care about the first two components of\'a0
\f2\fs36 \cf11 \cb12 inputTextureCoordinate
\f0\fs40 \cf6 \cb1 , X and Y. Instead of feeding more attributes than we need to to our fragment shader, we are stripping out the ones we need and assigning them to a variable type that will talk to the fragment shader.\
		This vertex shader stays pretty much the same for all of our various image filter programs, so the rest of the shaders we will be focusing on for this article will be fragment shaders.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl680\partightenfactor0

\b\fs57\fsmilli28800 \cf6 The Fragment Shader\

\f1 \'b9\'fd\'c2\'cb\'c6\'f7
\f0  + ---
\f1 \'be\'f6\'b6\'a8\'cf\'f1\'cb\'d8\'d1\'d5\'c9\'ab
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 Now that we have gone over our simple vertex shader, let\'92s take a look at the simplest fragment shader you can implement \'97 a passthrough filter:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 varying highp vec2 textureCoordinate;\
uniform sampler2D inputImageTexture;\
void main()\
\{\
    gl_FragColor = texture2D(inputImageTexture, textureCoordinate);\
\}\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		This shader isn\'92t really changing anything in our image. It\'92s a passthrough shader, which pretty much means we are inputting each pixel and outputting the exact same one
\f1 \'ca\'e4\'c8\'eb\'cf\'f1\'cb\'d8\'b5\'c8\'d3\'da\'ca\'e4\'b3\'f6\'cf\'f1\'cb\'d8
\f0 . Let\'92s also go through this piece by piece:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 varying highp vec2 textureCoordinate;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		Since the fragment shader works on each and every pixel
\f1 \'b4\'a6\'c0\'ed\'c3\'bf\'d2\'bb\'b8\'f6\'cf\'f1\'cb\'d8
\f0 , we need a way to determine which pixel/fragment we are currently analyzing
\f1 \'d2\'bb\'b8\'f6\'be\'f6\'b6\'a8\'b5\'b1\'c7\'b0\'b7\'d6\'ce\'f6\'b5\'c4\'ca\'c7\'c4\'c4\'b8\'f6\'cf\'f1\'cb\'d8\'bb\'f2\'ca\'c7\'c6\'ac\'b6\'ce\'b5\'c4\'b7\'bd\'b7\'a8
\f0 . It needs to store both the X and the Y coordinate for the pixel. We are receiving the current texture coordinate that was set up in the vertex shader
\f1 \'b4\'d3\'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7\'bd\'d3\'ca\'d5 \'b5\'b1\'c7\'b0\'ce\'c6\'c0\'ed\'d7\'f8\'b1\'ea
\f0 .\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 uniform sampler2D inputImageTexture;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		In order to process an image, we are receiving a reference to the image from the application, which we are treating as a 2D texture. The reason this data type is called a\'a0
\f2\fs36 \cf11 \cb12 sampler2D
\f0\fs40 \cf6 \cb1 \'a0is because we are using the shader to go in and pluck out a point in that 2D texture to process.
\f1 \'cc\'e1\'b9\'a9\'ce\'c6\'c0\'ed\'ca\'fd\'be\'dd
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 gl_FragColor = texture2D(inputImageTexture, textureCoordinate);\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		This is our first encounter with a GLSL-specific function:\'a0
\f2\fs36 \cf11 \cb12 texture2D
\f0\fs40 \cf6 \cb1 \'a0is a function that, just as it sounds, creates a 2D texture. It takes our properties declared above as parameters to determine the exact color of the pixel being analyzed
\f1 \'cd\'a8\'b9\'fd\'b7\'d6\'ce\'f6\'be\'f6\'b6\'a8 \'cf\'f1\'cb\'d8\'b5\'c4\'be\'df\'cc\'e5\'d1\'d5\'c9\'ab
\f0 . This is then set to our other built-in variable,\'a0
\f2\fs36 \cf11 \cb12 gl\\_FragColor
\f0\fs40 \cf6 \cb1 . Since the only purpose of a fragment shader
\f1 \'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7\'ce\'a8\'d2\'bb\'b5\'c4\'c4\'bf\'b5\'c4
\f0  is to determine what color a pixel is,\'a0
\f2\fs36 \cf11 \cb12 gl\\_FragColor 
\f0\fs40 \cf6 \cb1 essentially acts as a return statement for our fragment shader. Once the fragment color is set, there is no longer any point in continuing to do anything else in a fragment shader, so if you write any code after this line, it will not be processed.\
		As you can see, a vital part of writing shaders is to understand the shading language
\f1 \'c0\'ed\'bd\'e2\'d7\'c5\'c9\'ab\'d3\'ef\'d1\'d4
\f0 . Even though the shading language is based on C, there are lots of quirks and nuances that differentiate it from plain, vanilla C.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 GLSL Data Types and Operations\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		Shaders of all flavors 
\f1 \'b8\'f7\'d6\'d6\'d7\'c5\'c9\'ab\'c6\'f7
\f0  are written in the OpenGL Shading Language (GLSL). GLSL is a simple language derived from C 
\f1 \'bc\'cc\'b3\'d0\'d3\'da
\f0 C
\f1 \'b5\'c4\'bc\'f2\'bb\'af\'d3\'ef\'d1\'d4\'a3\'ac\'c8\'b1\'b7\'a6\'d2\'bb\'d0\'a9\'b8\'df\'bc\'b6\'cc\'d8\'d0\'d4\'a3\'ac\'c8\'e7\'b6\'af\'cc\'ac\'c4\'da\'b4\'e6\'b9\'dc\'c0\'ed
\f0 . It is lacking in some of the more advanced features of C, such as dynamic memory management. However, it also contains a lot of specialized functionality to process commonly used mathematical functions in the shading process.
\f1 \'d7\'c5\'c9\'ab\'b9\'fd\'b3\'cc\'d6\'d0\'b3\'a3\'bc\'fb\'b5\'c4\'ca\'fd\'d1\'a7\'ba\'af\'ca\'fd
\f0 \
		The Khronos Group, which is responsible for maintaining OpenGL and OpenGL ES, has reference materials for both available through its website. One of the most valuable things you can do for yourself when you are starting out is obtaining the Language Quick Reference cards for OpenGL ES and OpenGL:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl580\partightenfactor0
\ls3\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "https://www.khronos.org/opengles/sdk/docs/reference_cards/OpenGL-ES-2_0-Reference-card.pdf"}}{\fldrslt \expnd0\expndtw0\kerning0
OpenGL ES}}\cf6 \expnd0\expndtw0\kerning0
\
\ls3\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "https://www.khronos.org/files/opengl-quick-reference-card.pdf"}}{\fldrslt \expnd0\expndtw0\kerning0
OpenGL}}\cf6 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 		These cards contain a quick and easy way to look over the language for the function or data type information you need to write an OpenGL application.\
Use these early. Use them often.\
		There are quite a few things in even that simple shader that look completely alien, aren\'92t there? Now that we\'92ve had a chance to take a look at a very basic shader, it\'92s time to start explaining what some of its contents are, and why we have them in GLSL.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 Inputs, Outputs, and Precision Qualifiers
\f1 \'be\'ab\'b6\'c8\'cf\'de\'d6\'c6\'b7\'fb
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		If you look at our passthrough shader, you will notice that we had \
				one property that was labeled \'93varying,\'94\
				and another one that was labeled \'93uniform.\'94\
		These variables are our inputs and outputs in GLSL
\f1 \'d5\'e2\'d0\'a9\'b1\'e4\'c1\'bf\'ca\'c7
\f0 GLSL
\f1 \'d6\'d0\'b5\'c4\'ca\'e4\'c8\'eb\'d3\'eb\'ca\'e4\'b3\'f6
\f0 . They allow input from our application
\f1 \'b4\'d3\'d3\'a6\'d3\'c3\'ca\'e4\'c8\'eb
\f0  and communication from the vertex shader 
\f1 \'be\'ad\'b9\'fd\'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7
\f0 to the fragment shader
\f1 \'ca\'e4\'b3\'f6\'b5\'bd\'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7
\f0 .\
\
There are actually three labels 
\f1 \'c8\'fd\'d6\'d6\'b1\'ea\'ba\'c5\'d0\'de\'ca\'ce
\f0 GLSL
\f1 \'d6\'d0\'b5\'c4\'b1\'e4\'c1\'bf
\f0  we can assign to our variables in GLSL:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl580\partightenfactor0
\ls4\ilvl0\cf6 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
Uniforms 
\f1 \'b6\'a5\'b5\'e3
\f0  +
\f1 \'c6\'ac\'b6\'ce  ---- \'ca\'e4\'c8\'eb\'a1\'a3 \'cd\'e2\'b2\'bf\'ca\'c0\'bd\'e7\'d3\'eb\'d7\'c5\'c9\'ab\'c6\'f7\'cd\'a8\'d0\'c5\'b5\'c4\'ca\'d6\'b6\'ce\'a3\'ac\'d2\'bb\'b8\'f6\'e4\'d6\'c8\'be\'d6\'dc\'c6\'da\'c4\'da\'b2\'bb\'b8\'c4\'b1\'e4\'b8\'c3\'c0\'e0\'b1\'e4\'c1\'bf\'d4\'da\'d2\'bb\'b8\'f6\'e4\'d6\'c8\'be\'d6\'dc\'c6\'da\'c4\'da\'b2\'bb\'b8\'c4\'b1\'e4\'a3\'ac
\f0 \
\ls4\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
Attributes 
\f1 \'b6\'a5\'b5\'e3      \'ca\'e4\'c8\'eb\'d6\'b5\'a3\'ac\'cb\'e6\'b6\'a5\'b5\'e3\'b6\'f8\'b8\'c4\'b1\'e4\'a3\'ac\'c8\'e7\'ce\'bb\'d6\'c3\'ba\'cd\'ce\'c6\'c0\'ed\'d7\'f8\'b1\'ea\'a3\'ac
\f0 \
\ls4\ilvl0\kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
Varyings
\f1  \'b6\'a5\'b5\'e3
\f0  +
\f1 \'c6\'ac\'b6\'ce  --- \'b6\'a5\'b5\'e3
\f0  
\f1 \'b4\'ab\'b5\'dd\'b5\'bd
\f0  
\f1 \'c6\'ac\'b6\'ce\
\ls4\ilvl0
\f0 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 		Uniforms are one way for the outside world to communicate with your shaders. Uniforms are designed for input values that aren\'92t going to change within a render cycle
\f1 \'d2\'bb\'b8\'f6\'e4\'d6\'c8\'be\'d6\'dc\'c6\'da\'c4\'da\'b2\'bb\'b8\'c4\'b1\'e4
\f0 . If you are applying a sepia filter and you need to specify the strength of the filter, this is something that isn\'92t going to change within a render pass, so you\'92d send it in as a uniform. Uniforms can be accessed in both the vertex and the fragment shader. 
\f1 \'b6\'a5\'b5\'e3
\f0  +
\f1 \'c6\'ac\'b6\'ce\

\f0 \
		Attributes are only available in the vertex shader. Attributes are the input values that change with each vertex, such as its position and texture coordinate. The vertex shader takes in these values and either uses them to calculate the position, or passes values based on them along to the fragment shader in varyings.
\f1 \'b6\'a5\'b5\'e3\'a1\'a3  \'ca\'e4\'c8\'eb\'a1\'a3\'b0\'e9\'cb\'e6\'c3\'bf\'b8\'f6\'b6\'a5\'b5\'e3\'b6\'f8\'b8\'c4\'b1\'e4 \'a3\'ac\'c8\'e7\'ce\'bb\'d6\'c3\'d3\'eb\'ce\'c6\'c0\'ed\'d7\'f8\'b1\'ea \'a3\'ac\'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7\'b2\'c9\'d3\'c3\'d5\'e2\'d0\'a9\'d6\'b5 \'c0\'b4\'bc\'c6\'cb\'e3\'ce\'bb\'d6\'c3\'a1\'a2\'bb\'f2\'ca\'c7\'bb\'f9\'d3\'da\'cb\'fc\'c3\'c7\'c0\'b4\'b4\'ab\'b5\'dd\'d6\'b5\'b5\'bd\'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7\'a1\'a3\

\f0 \
		Last, but not least, we have varyings. Varyings are present in both the vertex and the fragment shader. Varyings are used to pass information from the vertex shader to the fragment shader, and must have matching names in both
\f1 \'b6\'fe\'d5\'df\'d6\'d0\'c3\'fb\'b3\'c6\'b6\'d4\'d3\'a6\'a3\'ac\'d3\'c3\'c0\'b4\'b4\'ab\'b5\'dd\'d0\'c5\'cf\'a2
\f0 . Values are written to varyings in the vertex shader and read in the fragment shader
\f1 \'d6\'b5\'b1\'bb\'d0\'b4\'c8\'eb\'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7\'d6\'d0\'b1\'e4\'c1\'bf\'a3\'ac\'b1\'bb\'b4\'d3\'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7\'d6\'d0\'b6\'c1\'b3\'f6
\f0 . Values written into varyings are interpolated between vertices for each of the between-vertex pixels acted on by a fragment shader.
\f1 \'b6\'a5\'b5\'e3
\f0  +
\f1 \'c6\'ac\'b6\'ce\'a1\'a3\'b6\'a5\'b5\'e3\'b2\'e5\'d6\'b5 \'d0\'b4\'c8\'eb\'b1\'e4\'c1\'bf \

\f0 		If you look back at our simple shader example, we had a varying declared in both the vertex and the fragment shader:\'a0
\f2\fs36 \cf11 \cb12 textureCoordinate
\f0\fs40 \cf6 \cb1 . We wrote the value of that varying in the vertex shader. We then passed it to the fragment shader, where it was read and processed.\
\
		One last quick thing to mention before we move on. Look at those variables you created. You will notice that your texture coordinate has an attribute called \'93highp.\'94 This attribute is setting the precision you need for this variable. Since OpenGL ES was designed to be on systems with limited processing power, precision qualifiers were added for efficiency.
\f1 \'be\'ab\'b6\'c8\'cf\'de\'d6\'c6\'b7\'fb  \'d0\'a7\'c2\'ca
\f0 \
		If you have something that doesn\'92t have to be very precise, you can indicate that and possibly allow more of these values to be operated on in a single clock cycle. On the other hand, in the case of the texture coordinate, we care a great deal about making sure this is as precise as possible, so we specify that we do indeed need this extra precision.\
		Precision qualifiers exist in OpenGL ES ES
\f1 \'d6\'d0\'c3\'bb\'d3\'d0
\f0 because they are geared toward mobile devices. However, they are missing in older versions of desktop OpenGL. Since OpenGL ES is effectively a subset of OpenGL, you can almost always directly port an OpenGL ES project to OpenGL. If you do that, however, you need to remember to strip the precision qualifiers out of your desktop shaders. This is an important thing to keep in mind, especially if you are planning to port your application between iOS and OS X.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 Vectors\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		You are going to work with a lot of vectors and vector types in GLSL. Vectors are a slightly tricky topic in that they are seemingly straightforward, but since they are so versatile, there is a lot of information out there that can be confusing about them.\
		In the context of GLSL, vectors are a specialized data type similar to an array
\f1 \'cf\'f2\'c1\'bf\'ca\'c7\'d3\'eb\'ca\'fd\'d7\'e9\'cf\'e0\'cb\'c6\'b5\'c4\'cc\'d8\'ca\'e2\'ca\'fd\'be\'dd\'c0\'e0\'d0\'cd
\f0 . Each type has a fixed value of elements that it can hold. If you dig in a little further, you can get even more specialized about the exact type of number value the array can hold, but for most purposes, sticking to the generic vector types will work just fine.\
		There are three vector types you will see over and over again:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl520\partightenfactor0
\ls5\ilvl0
\f2\fs36 \cf11 \cb12 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
vec2
\f0\fs40 \cf6 \cb1  
\f2\fs36 \cf11 \cb12 vec3
\f0\fs40 \cf6 \cb1  
\f2\fs36 \cf11 \cb12 vec4
\f0\fs40 \cf6 \cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 		These vector types contain a specified number of floating-point values:\'a0
\f2\fs36 \cf11 \cb12 vec2
\f0\fs40 \cf6 \cb1 contains two floating-point values,\'a0
\f2\fs36 \cf11 \cb12 vec3
\f0\fs40 \cf6 \cb1 \'a0contains three floating-point values, and\'a0
\f2\fs36 \cf11 \cb12 vec4
\f0\fs40 \cf6 \cb1 \'a0contains four floating-point values.\
		These types can be applied to several kinds of data you want to modify and persist in your shaders. One of the more obvious things you would want to keep track of is the X and Y coordinates of your fragment. An (X,Y) would fit quite nicely into the\'a0
\f2\fs36 \cf11 \cb12 vec2
\f0\fs40 \cf6 \cb1 \'a0data type.\
		Another thing that you tend to keep track of in graphics processing is the red, green, blue, and alpha value of each pixel. Those can be nicely stored in a\'a0
\f2\fs36 \cf11 \cb12 vec4
\f0\fs40 \cf6 \cb1 data type.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 Matrices\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		Now that we have a handle on vectors, let\'92s move on to matrices. Matrices are very similar to vectors, but they add an additional layer of complexity. Instead of simply being an array of floating-point values, matrices are an array of an array of floating-point values.\
		As with vectors, the matrix objects you are going to deal with most often are:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl520\partightenfactor0
\ls6\ilvl0
\f2\fs36 \cf11 \cb12 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
mat2
\f0\fs40 \cf6 \cb1 \
\ls6\ilvl0
\f2\fs36 \cf11 \cb12 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
mat3
\f0\fs40 \cf6 \cb1 \
\ls6\ilvl0
\f2\fs36 \cf11 \cb12 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
mat4
\f0\fs40 \cf6 \cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 		Where\'a0
\f2\fs36 \cf11 \cb12 vec2
\f0\fs40 \cf6 \cb1 \'a0holds two floating-point values,\'a0
\f2\fs36 \cf11 \cb12 mat2
\f0\fs40 \cf6 \cb1 \'a0holds the equivalent of two\'a0
\f2\fs36 \cf11 \cb12 vec2
\f0\fs40 \cf6 \cb1 \'a0objects. You don\'92t need to pass vector objects into your matrix objects, as long as you account for the correct number of floating-point elements needed to fill the matrix. In the case of the\'a0
\f2\fs36 \cf11 \cb12 mat2
\f0\fs40 \cf6 \cb1 \'a0object, you would either need to pass in two\'a0
\f2\fs36 \cf11 \cb12 vec2
\f0\fs40 \cf6 \cb1 \'a0objects or four floating-point values. Since you can name your vectors and you would only be responsible for two objects instead of four, it is highly encouraged for you to encapsulate your numbers in values that you can keep track of more easily. This only gets more complex when you move on to the\'a0
\f2\fs36 \cf11 \cb12 mat4
\f0\fs40 \cf6 \cb1 \'a0object and you are responsible for 16 numbers instead of 4!\
		In our\'a0
\f2\fs36 \cf11 \cb12 mat2
\f0\fs40 \cf6 \cb1 \'a0example, we have two sets of\'a0
\f2\fs36 \cf11 \cb12 vec2
\f0\fs40 \cf6 \cb1 \'a0objects. Each\'a0
\f2\fs36 \cf11 \cb12 vec2
\f0\fs40 \cf6 \cb1 \'a0object represents a row. The first element of each\'a0
\f2\fs36 \cf11 \cb12 vec2
\f0\fs40 \cf6 \cb1 \'a0represents a column. It\'92s very important to make sure that you are placing each value in the correct row and column when you are constructing your matrix object, or else the operations you perform on them will not work successfully.\
		So now that we have matrices and vectors to fill the matrices, the important question is: \'93What do we do with these?\'94 We can store points and colors and other bits of information, but how does that get us any closer to making something cool by modifying them?\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 Vector and Matrix Operations, AKA Linear Algebra 101\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		One of the best resources I have found out there to simply explain how linear algebra and matrices work
\f1 \'cf\'df\'d0\'d4\'b4\'fa\'ca\'fd\'d3\'eb\'be\'d8\'d5\'f3\'c8\'e7\'ba\'ce\'b9\'a4\'d7\'f7
\f0  is the site\'a0{\field{\*\fldinst{HYPERLINK "http://betterexplained.com/articles/linear-algebra-guide/"}}{\fldrslt \cf7 Better Explained}}. One of the quotes I have stolen, er, borrowed from this site is the following:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf13 		The survivors of linear algebra classes are physicists, graphics programmers, and other masochists.
\f1 \'cf\'df\'d0\'d4\'b4\'fa\'ca\'fd\'bf\'ce\'b3\'cc\'b5\'c4\'d0\'d2\'b4\'e6\'d5\'df\'ca\'c7\'ce\'ef\'c0\'ed\'d1\'a7\'bc\'d2\'a1\'a2\'cd\'bc\'d0\'ce\'b3\'cc\'d0\'f2\'d4\'b1\'ba\'cd\'c6\'e4\'cb\'fb\'ca\'dc\'c5\'b0\'bf\'f1\'a1\'a3
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 		Matrix operations generally aren\'92t \'93hard\'94; they just are not explained with any kind of context, so it\'92s difficult to conceptualize why on earth anyone would want to work with them. Hopefully by giving a little bit of context insofar as how they are utilized in graphics programming, we can get a sense of how they can help us implement awesome stuff.
\f1 \'b8\'f8\'b3\'f6\'ca\'b9\'d3\'c3\'b3\'a1\'be\'b0\'a3\'ac\'c0\'ed\'bd\'e2\'be\'d8\'d5\'f3\'c4\'dc\'b9\'bb\'b4\'a6\'c0\'ed\'b5\'c4\'bf\'c9\'c5\'c2\'b5\'c4\'c7\'e9\'bf\'f6
\f0 \
		Linear algebra allows you to perform an action on many values at the same time
\f1 \'d4\'da\'ba\'dc\'b6\'e0\'d6\'b5\'c9\'cf\'d6\'b4\'d0\'d0\'cd\'ac\'d2\'bb\'b8\'f6\'b2\'d9\'d7\'f7\'a3\'ac\'b2\'a2\'d0\'d0\'b2\'d9\'d7\'f7
\f0 . Let\'92s say you have a group of numbers and you want to multiply each of them by two. You are transforming each number in a consistent way. Since the same operation is being done to each number, you can implement this operation in parallel.\
		One example we should be using but seem to be afraid of is that of\'a0
\f2\fs36 \cf11 \cb12 CGAffineTransforms
\f0\fs40 \cf6 \cb1 . An affine transform is simply an operation that changes the size, position, or rotation of a shape with parallel sides, like a square or a rectangle.\
		It isn\'92t super important at this juncture to break out the old slide rule and be able to sit down with a pad of graph paper and a pencil and calculate your own transforms. GLSL has a lot of built-in functions that do the messy work of calculating out your transforms for you
\f1 \'c4\'da\'d6\'c3\'ba\'af\'ca\'fd\'bc\'c6\'cb\'e3\'b1\'e4\'bb\'bb
\f0 . It\'92s just important to have an idea of how these functions are working under the hood.
\f1 \'d4\'da\'d2\'fd\'c7\'e6\'cf\'c2\'a3\'ac\'c4\'da\'d6\'c3\'ba\'af\'ca\'fd\'ca\'c7\'c8\'e7\'ba\'ce\'b9\'a4\'d7\'f7\'b5\'c4\'a1\'a3
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 GLSL-Specific Functions\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		We\'92re not going to go over all of the built-in functions for GLSL in this article, but a good resource for this can be found at\'a0{\field{\*\fldinst{HYPERLINK "http://www.shaderific.com/glsl-functions"}}{\fldrslt \cf7 Shaderific}}. The vast majority of the GLSL functions are derived from basic math operations that are present in the C Math Library, so it isn\'92t really a good use of time to explain what the sin function does. We\'92re going to stick to some of the more esoteric functions for the purposes of this article, in order to explain some of the nuances of how to get the best performance out of your GPU.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f2 \cf6 		step()
\f0\b :
\b0 \'a0One limitation that your GPU has is that it doesn\'92t really deal well with conditional logic
\f1 \'b6\'d4\'cc\'f5\'bc\'fe\'c2\'df\'bc\'ad\'b4\'a6\'c0\'ed\'b5\'c4\'b2\'bb\'ba\'c3
\f0 . The GPU
\f1 \'cf\'b2\'bb\'b6\'bd\'d3\'ca\'dc\'d2\'bb\'d0\'a1\'b4\'e9\'b2\'d9\'d7\'f7\'a3\'ac\'b2\'a2\'b0\'d1\'cb\'fc\'c3\'c7\'d3\'a6\'d3\'c3\'b5\'bd\'cb\'f9\'d3\'d0\'ca\'c2\'ce\'ef\'c9\'cf
\f0  likes to take a bunch of operations and just apply them to everything.
\f1 \'b7\'d6\'d6\'a7\'bb\'e1\'b5\'bc\'d6\'c2\'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7\'b5\'c4\'d1\'cf\'d6\'d8\'bd\'b5\'cb\'d9\'a3\'ac\'d3\'c8\'c6\'e4\'ca\'c7\'d4\'da\'d2\'c6\'b6\'af\'c9\'e8\'b1\'b8\'c9\'cf
\f0  Branching can lead to significant slowdowns in fragment shaders, particularly on mobile devices.\'a0
\f2\fs36 \cf11 \cb12 step()
\f0\fs40 \cf6 \cb1 \'a0
\f1 \'ca\'b9\'cc\'f5\'bc\'fe\'c2\'df\'bc\'ad\'ce\'de\'b7\'d6\'d6\'a7\'bb\'af\'a3\'ac\'c0\'b4\'c8\'c6\'b9\'fd\'d5\'e2\'b8\'f6\'cf\'de\'d6\'c6
\f0 works around this limitation somewhat by allowing conditional logic without branching. If a variable passed into a\'a0
\f2\fs36 \cf11 \cb12 step()
\f0\fs40 \cf6 \cb1 function is less than a threshold value,\'a0
\f2\fs36 \cf11 \cb12 step()
\f0\fs40 \cf6 \cb1 \'a0returns 0.0. If the variable is greater or equal, it returns 1.0. By multiplying this result times values in your shader, values can be used or ignored based on conditional logic, all without an\'a0
\f2\fs36 \cf11 \cb12 if()
\f0\fs40 \cf6 \cb1 \'a0statement.
\f1 \'cd\'a8\'b9\'fd\'bd\'ab\'b8\'c3\'bd\'e1\'b9\'fb\'b3\'cb\'d2\'d4\'d7\'c5\'c9\'ab\'c6\'f7\'d6\'d0\'b5\'c4\'d6\'b5\'a3\'ac\'bf\'c9\'d2\'d4\'bb\'f9\'d3\'da\'cc\'f5\'bc\'fe\'c2\'df\'bc\'ad\'ca\'b9\'d3\'c3\'bb\'f2\'ba\'f6\'c2\'d4\'d6\'b5\'a3\'ac\'b6\'f8\'b2\'bb\'d3\'c3
\f0 if()
\f1 \'d3\'ef\'be\'e4\'a1\'a3
\f0 \

\f2 		mix()
\f0\b :
\b0 \'a0The mix function blends two values (such as colors) to a variable degree. If we had two colors of red and green, we could linearly interpolate between them using a\'a0
\f2\fs36 \cf11 \cb12 mix()
\f0\fs40 \cf6 \cb1 \'a0function. This is commonly used in image processing to control the strength of an effect in response to a uniform set by the application.
\f1 \'d5\'e2\'cd\'a8\'b3\'a3\'d3\'c3\'d3\'da\'cd\'bc\'cf\'f1\'b4\'a6\'c0\'ed\'a3\'ac\'d2\'d4\'cf\'ec\'d3\'a6\'d3\'a6\'d3\'c3\'b3\'cc\'d0\'f2\'b5\'c4\'cd\'b3\'d2\'bb\'c9\'e8\'d6\'c3\'c0\'b4\'bf\'d8\'d6\'c6\'d0\'a7\'b9\'fb\'b5\'c4\'c7\'bf\'b6\'c8\'a1\'a3
\f0 \

\f2 		clamp()
\f0\b :
\b0 \'a0One of the consistent aspects of GLSL is that it likes to use normalized coordinates
\f1 \'b1\'ea\'d7\'bc\'d7\'f8\'b1\'ea
\f0 . It wants and expects to receive values between 0.0 and 1.0 for things like color components or texture coordinates. In order to make sure that our values don\'92t stray outside of this very narrow parameter, we can implement the\'a0
\f2\fs36 \cf11 \cb12 clamp()
\f0\fs40 \cf6 \cb1 function. The\'a0
\f2\fs36 \cf11 \cb12 clamp()
\f0\fs40 \cf6 \cb1 \'a0function checks to make sure your value is between 0.0 and 1.0. If your value is below 0.0, it will set its value to 0.0. This is done to avoid any general wonkiness that might arise if you are trying to do calculations and you accidentally receive a negative number or something that is entirely beyond the scope of the equation.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 More Complex Shader Examples\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		I realize that deluge of math must have felt very overwhelming. If you\'92re still with me, I want to walk through a couple of neat shader examples that will make a lot more sense now that you\'92ve have a chance to wade into the GLSL waters.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl680\partightenfactor0

\b\fs57\fsmilli28800 \cf6 Saturation Adjustment\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 {{\NeXTGraphic Saturation-2527a4b7.png \width12960 \height7660 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}}\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 \
		This is a fragment shader that does saturation adjustment
\f1 \'b1\'a5\'ba\'cd\'b6\'c8\'b5\'f7\'d5\'fb
\f0 . This shader is based off of code from the book \'93{\field{\*\fldinst{HYPERLINK "http://www.amazon.com/Graphics-Shaders-Theory-Practice-Second/dp/1568814348/ref=sr_1_1?s=books&ie=UTF8&qid=1422557718&sr=1-1&keywords=graphics+shaders+theory+and+practice"}}{\fldrslt \cf7 Graphics Shaders: Theory and Practice}},\'94 which I highly recommend to anyone interested in learning more about shaders.\
		Saturation is the term used to describe how bright and intense a color is. A bright red sweater is far more saturated than the gloomy, gray winter skies in rural Wisconsin.\
		There are some optimizations we can utilize in this shader that work with the way that human beings perceive color and contrast. Generally speaking, human beings are far more sensitive to brightness than we are to color. One optimization made over the years to our compression software is to pare back the amount of memory used to store color.\
		Not only are humans more sensitive to brightness than color, but we are also more responsive to certain colors within the brightness spectrum, specifically green. This means that when you are calculating out ways of compressing your photos or modifying their brightness or color in some way, it\'92s important to put more emphasis on the green part of the spectrum, because that is the one that we respond to the most:
\f1 \'b0\'d1\'b8\'fc\'b6\'e0\'b5\'c4\'d6\'d8\'b5\'e3\'b7\'c5\'d4\'da\'b9\'e2\'c6\'d7\'b5\'c4\'c2\'cc\'c9\'ab\'b2\'bf\'b7\'d6\'c9\'cf\'ba\'dc\'d6\'d8\'d2\'aa\'a3\'ac\'d2\'f2\'ce\'aa\'d5\'e2\'ca\'c7\'ce\'d2\'c3\'c7\'d7\'ee\'c8\'dd\'d2\'d7\'d7\'f6\'b3\'f6\'b7\'b4\'d3\'a6\'b5\'c4\'b2\'bf\'b7\'d6\'a3\'ba
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 varying highp vec2 textureCoordinate;\
\
uniform sampler2D inputImageTexture;\
uniform lowp float saturation;\
\
const mediump vec3 luminanceWeighting = vec3(0.2125, 0.7154, 0.0721);\
\
void main()\
\{\
   lowp vec4 textureColor = texture2D(inputImageTexture, textureCoordinate);\
   lowp float luminance = dot(textureColor.rgb, luminanceWeighting);\
   lowp vec3 greyScaleColor = vec3(luminance);\
\
    gl_FragColor = vec4(mix(greyScaleColor, textureColor.rgb, saturation), textureColor.w);\
\}\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 Let\'92s go through this fragment shader line by line:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 varying highp vec2 textureCoordinate;	//
\f0\fs40 \cf6 \cb1 input texture coordinate
\f2\fs34 \cf10 \cb9 \
\
uniform sampler2D inputImageTexture;	//
\f0\fs40 \cf6 \cb1 input image texture
\f2\fs34 \cf10 \cb9 \
uniform lowp float saturation;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		Again, since this is a fragment shader that is talking to our baseline vertex shader, we do need to declare varyings for our input texture coordinate and our input image texture, in order to receive the information we need to process our filter
\f1 \'d3\'c3\'c0\'b4\'bd\'d3\'ca\'d5\'b4\'a6\'c0\'ed\'b9\'fd\'c2\'cb\'c6\'f7\'b5\'c4\'d0\'c5\'cf\'a2
\f0 . We do have a new uniform that we are dealing with in this example, which is saturation. Saturation amount is a parameter we are set up to receive from the user interface. We need to know how much saturation the user wants in order to present the correct amount of color. 
\f1 \'d5\'fd\'c8\'b7\'b5\'c4\'d1\'d5\'c9\'ab\'d7\'dc\'c1\'bf
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 const mediump vec3 luminanceWeighting = vec3(0.2125, 0.7154
\f1 \'c2\'cc\'c9\'ab
\f2 , 0.0721
\f1 \'c0\'b6\'c9\'ab
\f2 );
\f1 \'c1\'c1\'b6\'c8
\f2 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		This is where we are setting up a three-component vector to store our color weighting for our luminance extraction. All three of these values must add up to 1.0 so that we can calculate the luminance of a pixel on a scale from 0.0 to 1.0. Notice that the middle number, which represents green, uses 70 percent of the available color weighting, while blue only uses a tenth of that. The blue doesn\'92t show up as well to us, and it makes more sense to instead weigh toward green for brightness.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 lowp vec4 textureColor = texture2D(inputImageTexture, textureCoordinate);\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		We need to capture the color information about our specific pixel 
\f1 \'b2\'b6\'bb\'f1\'cc\'d8\'b6\'a8\'cf\'f1\'cb\'d8\'b5\'c4\'d1\'d5\'c9\'ab\'d0\'c5\'cf\'a2
\f0 by sampling its exact coordinate within our image/texture. Instead of simply returning this value as we did with the passthrough filter, we are going to modify it and change it up a little.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 lowp float luminance = dot(textureColor.rgb, luminanceWeighting);
\f1 \'b8\'c4\'b1\'e4\'cf\'f1\'cb\'d8\'d6\'b5
\f2 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		This line will probably look unfamiliar to anyone who either never took linear algebra or who took it so long ago that dinosaurs were used to ride to school. We are using the dot product function from GLSL. If you remember using a dot symbol to multiply two numbers together in school, you\'92re on the right track here. The dot product is taking our\'a0
\f2\fs36 \cf11 \cb12 vec4
\f0\fs40 \cf6 \cb1 \'a0containing the texture color information for the fragment, dropping the last parameter because it won\'92t be needed, and multiplying it by its corresponding luminance weight. Then it is taking all three of those values and adding them together to figure out the overall luminance of the pixel.
\f1 \'cf\'f1\'cb\'d8\'d5\'fb\'cc\'e5\'b5\'c4\'c1\'c1\'b6\'c8\'d6\'b5
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 lowp vec3 greyScaleColor = vec3(luminance);\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		Now we are creating a\'a0
\f2\fs36 \cf11 \cb12 vec3
\f0\fs40 \cf6 \cb1 \'a0that contains the luminance for all three values. If you only specify one value, the compiler knows enough to set it for each slot in that vector .\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 gl_FragColor = vec4(mix(greyScaleColor, textureColor.rgb, saturation), textureColor.w);\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		Finally, we are putting all of our pieces together. In order to determine what the new value of each color is, we are applying our handy dandy mix function that we learned about a little while ago. The mix function is taking the grayscale color we just determined, combining it with the initial texture color, and basing the ratio of the mix on the information we are getting back about the saturation level.\
So here is a nice, handy shader that lets you change your image from color to grayscale and back with only four lines of code in the main function. Not too bad, huh? 
\f1 \'c9\'ab\'d6\'b5\'bb\'d2\'b6\'c8\'bb\'af \'bb\'f2\'ca\'c7 \'bb\'d2\'b6\'c8\'c9\'ab\'d6\'b5\'bb\'af
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl680\partightenfactor0

\b\fs57\fsmilli28800 \cf6 Sphere Refraction 
\f1 \'be\'b5\'c3\'e6\'b7\'b4\'c9\'e4
\f0 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 Finally, we\'92re going to go over a really nifty filter that you can pull out to impress your friends and terrify your enemies. This filter makes it look like there is a glass sphere sitting on top of your image. It\'92s going to be quite a bit more complicated than the previous ones, but I have confidence that we can do it!\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 {{\NeXTGraphic sphereRefraction-7115293d.png \width7200 \height12780 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}}\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 varying highp vec2 textureCoordinate;\
uniform sampler2D inputImageTexture;\
\
uniform highp vec2 center;\
uniform highp float radius;\
uniform highp float aspectRatio;\
uniform highp float refractiveIndex;\
\
void main()\
\{\
    highp vec2 textureCoordinateToUse = vec2(textureCoordinate.x, \
										(textureCoordinate.y * aspectRatio + 0.5 - 0.5 * aspectRatio));\
    highp float distanceFromCenter = distance(center, textureCoordinateToUse);\
    lowp float checkForPresenceWithinSphere = step(distanceFromCenter, radius);\
\
    distanceFromCenter = distanceFromCenter / radius;\
\
    highp float normalizedDepth = radius * sqrt(1.0 - distanceFromCenter * distanceFromCenter);\
    highp vec3 sphereNormal = normalize(vec3(textureCoordinateToUse - center, normalizedDepth));\
\
    highp vec3 refractedVector = refract(vec3(0.0, 0.0, -1.0), sphereNormal, refractiveIndex);\
\
    gl_FragColor = texture2D(inputImageTexture, (refractedVector.xy + 1.0) * 0.5) * checkForPresenceWithinSphere;\
\}\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 Once more, with feeling\'85\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 uniform highp vec2 center;\
uniform highp float radius;\
uniform highp float aspectRatio;\
uniform highp float refractiveIndex;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 We are bringing in a few parameters that we need in order to calculate out how much of our image is going to go through the filter. Since this is a sphere, we need a center point and a radius to calculate where the edges of the sphere are. The aspect ratio is determined by the screen size of whatever device you are using, so it can\'92t be hardcoded, because an iPhone has a different screen ratio than an iPad does. Our user or the programmer will decide what he or she wants the refractive index to be to determine how the refraction looks. The refractive index set in GPUImage is 0.71.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 highp vec2 textureCoordinateToUse = vec2(textureCoordinate.x, (textureCoordinate.y * aspectRatio + 0.5 - 0.5 * aspectRatio));\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 The texture coordinates of our image are in a normalized 0.0-1.0 coordinate space. This means that instead of thinking of the phone as being 320 pixels across and 480 pixels high, the screen is one unit long and one unit wide. Since the phone is taller than it is long, we need to calculate an offset ratio for our sphere so that the sphere is round instead of oval:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 {{\NeXTGraphic aspectRatio-4b7d1286.png \width6940 \height4840 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}}\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 highp float distanceFromCenter = distance(center, textureCoordinateToUse);\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 We need to calculate how far away from the center of the sphere our specific pixel is. We are using the\'a0
\f2\fs36 \cf11 \cb12 distance()
\f0\fs40 \cf6 \cb1 \'a0function built into GLSL, which takes the Pythagorean distance between the center coordinate and the aspect-ratio-corrected texture coordinate.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 lowp float checkForPresenceWithinSphere = step(distanceFromCenter, radius);\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 Here is where we are going to figure out if our fragment resides within the sphere. We are checking to see how far away we are from the center of the sphere and what the radius is. If our distance is shorter than the radius, then the fragment exists within the sphere and this variable is set to 1.0. If, however, the distance from the center is longer than the radius, the fragment does not live within the sphere and this gets set to 0.0:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 {{\NeXTGraphic distanceFromCenter2-67f35003.png \width7440 \height10940 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}}\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 distanceFromCenter = distanceFromCenter / radius;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 Now that we have determined which pixels exist within the sphere, we are going to move on to calculating what to do with the ones that do exist in the sphere. Again, we need to normalize our distance from the center. Rather than creating a whole new variable, which adds to the overhead in our program, we are going to reset the\'a0
\f2\fs36 \cf11 \cb12 distanceFromCenter
\f0\fs40 \cf6 \cb1 \'a0variable. By dividing it by the radius, we are making our math calculations easier in the next few lines of code.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 highp float normalizedDepth = radius * sqrt(1.0 - distanceFromCenter * distanceFromCenter);\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 Since we are trying to emulate a glass sphere, we need to figure out how \'93deep\'94 the sphere is. The virtual sphere, for all intents and purposes, is extending a distance up from the image surface toward the viewer in the z-axis. This is going to be used to help the computer figure out how to model the pixels that exist within the sphere. Also, since a sphere is round, there will be different depths for the sphere depending upon how far away you are from the center. The center of the sphere will refract light differently than the edges, due to the different orientations of the surface:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 {{\NeXTGraphic normalizedDepth-39a84484.png \width10020 \height3360 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}}\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 highp vec3 sphereNormal = normalize(vec3(textureCoordinateToUse - center, normalizedDepth));\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 Again, we are back to normals, huzzah. To describe the orientation of the sphere surface at a point, we take the distance of the current pixel from the center of the sphere in X and Y, and combine those components with the sphere depth we calculated. We then normalize the resulting vector to have a length of one.\
Think about when you are using something like Adobe Illustrator. You create a triangle in Illustrator, but it\'92s too small. You hold down the option key and you resize the triangle, except now it\'92s too big. You then scale it down to get it to be the exact size you want:\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 {{\NeXTGraphic sphereNormal-0ff5ddca.png \width10020 \height3380 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}}\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 highp vec3 refractedVector = refract(vec3(0.0, 0.0, -1.0), sphereNormal, refractiveIndex);\
\pard\pardeftab720\li600\fi-14\ri-9798\sl540\partightenfactor0

\fs36 \cf11 \cb12 refract()
\f0\fs40 \cf6 \cb1 \'a0is a fun GLSL function.\'a0
\f2\fs36 \cf11 \cb12 refract()
\f0\fs40 \cf6 \cb1 \'a0is taking in the sphere normal we just created and using the refractive index to calculate how light passing through a sphere of this type would look at any given point.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl220\qc\partightenfactor0

\b\fs23\fsmilli11900 \cf8 \cb9 SELECT ALL\cb1 \
\pard\pardeftab720\li600\fi-14\ri-9798\sl420\partightenfactor0

\f2\b0\fs34 \cf10 \cb9 gl_FragColor = texture2D(inputImageTexture, (refractedVector.xy + 1.0) * 0.5) * checkForPresenceWithinSphere;\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\f0\fs40 \cf6 \cb1 		Finally, after jumping through all these hoops, we have gathered together all of the pieces we need to figure out what color to use for the fragment. The refracted light vector is used to find which location on the input image to read from, but because the coordinates in that vector range from \uc0\u8722 1.0 to 1.0, we adjust that to lie within the 0.0\'961.0 texture coordinate space.\
		We then multiply our effect by the value we got from our sphere bounds check. If our fragment doesn\'92t lie within the sphere, a transparent pixel (0.0, 0.0, 0.0, 0.0) is written. If the fragment is present within the sphere, the effect is applied and the calculated color returned. This allows us to avoid expensive conditional logic for the shader.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 Debugging Shaders\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		Debugging shaders is not a straightforward task. In your normal program, if the program crashes, you can set a breakpoint. That isn\'92t really possible to do on an operation that gets called in parallel millions of times a second. It also isn\'92t feasible to use\'a0
\f2\fs36 \cf11 \cb12 printf()
\f0\fs40 \cf6 \cb1 \'a0statements in your shaders to debug what is going wrong, because where would the output even go? Given that your shaders seem to be living in a black box, how do you crack them open to find out why they aren\'92t working?
\f1 \'b0\'d1\'d7\'c5\'c9\'ab\'c6\'f7\'cf\'eb\'cf\'f3\'ce\'aa\'d2\'bb\'b8\'f6\'ba\'da\'ba\'d0\'d7\'d3
\f0 \
		You have one output at your disposal: our old friend\'a0
\f2\fs36 \cf11 \cb12 gl\\_FragColor
\f0\fs40 \cf6 \cb1 .\'a0
\f2\fs36 \cf11 \cb12 gl\\_FragColor
\f0\fs40 \cf6 \cb1 \'a0gives you an output that, with a little lateral thinking, you can use to debug your code. 
\f2\fs36 \cf11 \cb12 gl\\_FragColor
\f0\fs40 \cf6 \cb1 \
		All colors you see on the screen are represented by a series of numbers, which are 
\f1 \'b0\'d9\'b7\'d6\'b1\'c8
\f0 a percentage of the amount of red, green, blue, and opacity each individual pixel contains. You can use this knowledge to test each part of your shader as you construct it to make sure that it is performing the way you would like. ---------Instead of getting back a printed value, you would get back a color with a specific associated value that you can reverse engineer. \
		If you want to know the value of one of your variables that is between zero and one, you can set it to part of the\'a0
\f2\fs36 \cf11 \cb12 vec4
\f0\fs40 \cf6 \cb1 \'a0that gets passed to the\'a0
\f2\fs36 \cf11 \cb12 gl\\_FragColor
\f0\fs40 \cf6 \cb1 . Let\'92s say you set it to the first part, which is the red value. That value will be converted and rendered to the screen, at which point you can examine it to determine what the original value was that was passed in.\
		You can then capture these values in a couple of ways. The output image from your shader could be captured and written to disk as an image (preferably in an uncompressed format). This image could then be pulled into an application like Photoshop and the pixel colors examined.\
		For faster turnaround, you could render your image to the screen in an OS X application, or an iOS one running in the Simulator. To analyze these rendered views, there is a tool included in your Utilities folder in your Applications folder called \'93Digital Color Meter
\f1 \'ca\'fd\'d7\'d6\'b2\'e2\'c9\'ab\'d2\'c7
\f0 .\'94 If you hover your mouse over any pixel on your desktop, it will show you the exact RGB component of that pixel. Since RGB values in Digital Color Meter and Photoshop are from 0 to 255 instead of 0 to 1, you need to divide the specific value you want by 255 to get an approximate value of what the initial passed-in value was.\
		Let\'92s look back at our sphere refraction shader. We wouldn\'92t want to try to write the whole shader without doing any debugging on it. We have the specific chunk of code to determine if the pixel we are currently looking at is within the circle or not. That block of code ends with a\'a0
\f2\fs36 \cf11 \cb12 step()
\f0\fs40 \cf6 \cb1 \'a0function that sets the value of a pixel to either 0.0 or 1.0.\
		If you passed a\'a0
\f2\fs36 \cf11 \cb12 vec4
\f0\fs40 \cf6 \cb1 \'a0to the\'a0
\f2\fs36 \cf11 \cb12 gl\\_FragColor
\f0\fs40 \cf6 \cb1 , where the red value was whatever the\'a0
\f2\fs36 \cf11 \cb12 step()
\f0\fs40 \cf6 \cb1 \'a0function value was, and the other two colors were set to 0.0, you should see a red circle on a black screen if your code is working properly. If the whole screen is either black or red, then something has gone terribly wrong.\
\pard\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 Performance Tuning\
\pard\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 		Performance tuning and profiling
\f1 \'d0\'d4\'c4\'dc\'b5\'f7\'d5\'fb\'ba\'cd\'b7\'d6\'ce\'f6
\f0  are incredibly important things to do, especially if you are trying to target your application to run smoothly on older iOS devices.\
		Profiling your shader is important
\f1 \'b6\'d4\'d7\'c5\'c9\'ab\'c6\'f7\'bd\'f8\'d0\'d0\'b7\'d6\'ce\'f6\'ca\'c7\'d6\'d8\'d2\'aa\'b5\'c4
\f0 , because you can\'92t always be sure how performant something will be. Shader performance changes in nonintuitive 
\f1 \'b7\'c7\'d6\'b1\'be\'f5\'b5\'c4
\f0 ways. You might find a great optimization on Stack Overflow that does nothing to speed up your shader because you didn\'92t optimize where the actual bottleneck was in your processing code. Even switching a couple of lines of code in your project can vastly increase or decrease the amount of time it takes for your frame to render. 
\f1 \'b4\'fa\'c2\'eb\'cb\'b3\'d0\'f2
\f0  \
		When profiling, I recommend measuring frame rendering time
\f1 \'b2\'e2\'c1\'bf\'d6\'a1\'e4\'d6\'c8\'be\'ca\'b1\'bc\'e4\'a3\'ac\'b6\'f8\'b2\'bb\'ca\'c7\'d6\'a1\'c2\'ca
\f0 , rather than focusing on frames per second (FPS). Frame rendering time increases or decreases linearly with the performance of your shader, which makes it easy to see the impact you\'92re having. FPS is the inverse of frame time, and it can be harder to understand when tuning. Lastly, if you\'92re capturing from the iPhone\'92s video camera
\f1 \'b2\'b6\'bb\'f1\'ca\'d3\'c6\'b5\'c9\'e3\'cf\'f1\'cd\'b7
\f0 , it will adjust incoming FPS depending upon the lighting in your scene 
\f1 \'b8\'f9\'be\'dd\'b3\'a1\'be\'b0\'b5\'c4\'b9\'e2\'cf\'df\'b5\'f7\'d5\'fb
\f0 FPS, which can lead to incorrect measurements if you rely on that
\f1 \'b5\'bc\'d6\'c2\'b2\'bb\'d5\'fd\'c8\'b7\'b5\'c4\'b2\'e2\'c1\'bf
\f0 .\
		The frame rendering time is the amount of time it takes for the
\f1 \'d6\'a1\'bf\'aa\'ca\'bc\'b4\'a6\'c0\'ed
\f0  frame to begin processing until it completely finishes and is rendered to the screen or to a final image
\f1 \'cd\'ea\'b3\'c9\'e4\'d6\'c8\'be\'b5\'bd\'c6\'c1\'c4\'bb\'bb\'f2\'ca\'c7\'d7\'ee\'d6\'d5\'b5\'c4\'cd\'bc\'c6\'ac
\f0 . Many mobile GPUs use a technique called \'93deferred rendering
\f1 \'d1\'d3\'b3\'d9\'e4\'d6\'c8\'be
\f0 ,\'94 where rendering instructions are batched up and executed only as needed
\f1 \'b4\'f2\'b0\'fc\'e4\'d6\'c8\'be\'d6\'b8\'c1\'ee\'a3\'ac\'d0\'e8\'d2\'aa\'ca\'b1\'d4\'d9\'d6\'b4\'d0\'d0
\f0 . Therefore, it\'92s important to measure the entire rendering operation, rather than operations in the middle, because they may run in a different order than you expect.
\f1 \'d2\'aa\'b2\'e2\'c1\'bf\'d5\'fb\'b8\'f6\'b5\'c4\'e4\'d6\'c8\'be\'b2\'d9\'d7\'f7\'a3\'ac\'b6\'f8\'b2\'bb\'ca\'c7\'d6\'d0\'bc\'e4\'b5\'c4\'b2\'d9\'d7\'f7\'a3\'ac\'bf\'c9\'c4\'dc\'c2\'d2\'d0\'f2\'d6\'b4\'d0\'d0
\f0 \
		Optimizations can also vary wildly from device to device, desktop, and mobile. You may need to profile on multiple classes of devices. For example, the GPUs in mobile iOS devices have grown increasingly more powerful. The CPU on an iPhone 5S is approximately 10 times faster than the CPU on the iPhone 4, however its GPU is hundreds of times faster.\
		If you are testing your applications on devices with an A7 chip or higher, you are going to get vastly different results than you would with an iPhone 5 or lower.\'a0{\field{\*\fldinst{HYPERLINK "http://www.sunsetlakesoftware.com/2013/10/21/optimizing-gaussian-blurs-mobile-gpu"}}{\fldrslt \cf7 Brad Larson profiled how long a Gaussian Blur took on various iOS devices and has clearly demonstrated a dramatic leap forward in processing times on newer devices:}}\

\itap1\trowd \taflags0 \trgaph108\trleft-108 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalt \clshdrawnil \clwWidth640\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadr0 \gaph\cellx4320
\clvertalc \clshdrawnil \clwWidth17580\clftsWidth3 \clbrdrt\brdrs\brdrw20\brdrcf14 \clbrdrl\brdrs\brdrw20\brdrcf14 \clbrdrb\brdrs\brdrw20\brdrcf14 \clbrdrr\brdrs\brdrw20\brdrcf14 \clpadl100 \clpadr100 \gaph\cellx8640
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\partightenfactor0
\cf6 \cell 

\itap2\trowd \taflags1 \trgaph108\trleft-108 \tamart580 \trbrdrt\brdrnil \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalt\clvertalbase \clshdrawnil \clwWidth3290\clftsWidth3 \clmarr400 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb600 \clpadr400 \gaph\cellx4320
\clvertalt\clvertalbase \clshdrawnil \clwWidth7705\clftsWidth3 \clmarr400 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb600 \clpadr400 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0

\b \cf5 iPhone Version\nestcell 
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0
\cf5 Frame Rendering Time in Milliseconds 
\f1 \'ba\'c1\'c3\'eb \'ce\'a2\'c3\'eb \'c4\'c9\'c3\'eb
\f0 \nestcell \nestrow

\itap2\trowd \taflags1 \trgaph108\trleft-108 \tamart580 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalt\clvertalbase \clshdrawnil \clwWidth3290\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb400 \clpadr400 \gaph\cellx4320
\clvertalt\clvertalbase \clshdrawnil \clwWidth7705\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb400 \clpadr400 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0

\b0 \cf5 iPhone 4\nestcell 
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0
\cf5 873\nestcell \nestrow

\itap2\trowd \taflags1 \trgaph108\trleft-108 \tamart580 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalt\clvertalbase \clshdrawnil \clwWidth3290\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb400 \clpadr400 \gaph\cellx4320
\clvertalt\clvertalbase \clshdrawnil \clwWidth7705\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb400 \clpadr400 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0
\cf5 iPhone 4S\nestcell 
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0
\cf5 145\nestcell \nestrow

\itap2\trowd \taflags1 \trgaph108\trleft-108 \tamart580 \trbrdrl\brdrnil \trbrdrr\brdrnil 
\clvertalt\clvertalbase \clshdrawnil \clwWidth3290\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb400 \clpadr400 \gaph\cellx4320
\clvertalt\clvertalbase \clshdrawnil \clwWidth7705\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb400 \clpadr400 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0
\cf5 iPhone 5\nestcell 
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0
\cf5 55\nestcell \nestrow

\itap2\trowd \taflags1 \trgaph108\trleft-108 \tamart580 \trbrdrl\brdrnil \trbrdrt\brdrnil \trbrdrr\brdrnil 
\clvertalt\clvertalbase \clshdrawnil \clwWidth3290\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb400 \clpadr400 \gaph\cellx4320
\clvertalt\clvertalbase \clshdrawnil \clwWidth7705\clftsWidth3 \clbrdrt\brdrnil \clbrdrl\brdrnil \clbrdrb\brdrnil \clbrdrr\brdrnil \clpadl0 \clpadb400 \clpadr400 \gaph\cellx8640
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0
\cf5 iPhone 5S\nestcell 
\pard\intbl\itap2\pardeftab720\li600\fi-14\ri-9798\sl460\partightenfactor0
\cf5 3\nestcell \lastrow\nestrow
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 There is a tool that you can download,\'a0{\field{\*\fldinst{HYPERLINK "http://community.imgtec.com/developers/powervr/"}}{\fldrslt \cf7 Imagination Technologies PowerVR SDK}}, that will profile your shader and let you know the best- and worst-case performance for your shader rendering. It\'92s important to get the number of cycles necessary to render your shader as low as possible to keep your frame rate high. If you want to hit a target of 60 frames per second, you only have 16.67 milliseconds to get all of your processing done.16.67
\f1 \'ba\'c1\'c3\'eb
\f0 \
Here are some easy ways to help you hit your target:\
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl580\partightenfactor0
\ls7\ilvl0
\b \cf6 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
Eliminate conditional logic.
\b0 \'a0Sometimes it\'92s necessary to include conditional logic, but try to keep it to a minimum. Using workarounds 
\f1 \'b9\'a4\'d7\'f7\'c7\'f8
\f0  like the\'a0
\f2\fs36 \cf11 \cb12 step()
\f0\fs40 \cf6 \cb1 function can help you avoid expensive conditional logic in your shaders.
\f1 \'cf\'fb\'b3\'fd\'cc\'f5\'bc\'fe\'c2\'df\'bc\'ad
\f0 \
\ls7\ilvl0
\b \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
Reduce dependent texture reads.
\b0 \'a0Dependent texture reads occur when a texture is sampled in a fragment shader from a texture coordinate that wasn\'92t passed in directly as a varying, but was instead calculated in the fragment shader. These dependent texture reads can\'92t take advantage of optimizations in caching that normal texture reads do, leading to much slower reads. \
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl580\partightenfactor0
\ls7\ilvl0\cf6 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
For example, if you want to sample from nearby pixels, rather than calculate the offset to the neighboring pixel in your fragment shader, it\'92s best to do this calculation in the vertex shader and have the result be passed along as a varying. A demonstration of this is present in\'a0{\field{\*\fldinst{HYPERLINK "https://www.objc.io/issues/21-camera-and-photos/gpu-accelerated-machine-vision/"}}{\fldrslt \cf7 Brad Larson\'92s article}}, in the case of Sobel edge detection.
\f1 \'bd\'b5\'b5\'cd\'d2\'c0\'c0\'b5\'ce\'c6\'c0\'ed\'b6\'c1
\f0 \
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl580\partightenfactor0
\ls7\ilvl0
\b \cf6 \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
Make your calculations as simple as possible.
\b0 \'a0If you can avoid an expensive operation and get an approximate value that is good enough, you should do so. Expensive calculations include calling trigonometric functions (like\'a0
\f2\fs36 \cf11 \cb12 sin()
\f0\fs40 \cf6 \cb1 ,\'a0
\f2\fs36 \cf11 \cb12 cos()
\f0\fs40 \cf6 \cb1 , and\'a0
\f2\fs36 \cf11 \cb12 tan()
\f0\fs40 \cf6 \cb1 ).
\f1 \'bc\'f2\'bb\'af\'bc\'c6\'cb\'e3
\f0 \
\ls7\ilvl0
\b \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
Shift work over to the vertex shader, if it makes sense.
\b0 \'a0Our previous talk about dependent texture reads is a situation where it would make sense to move texture coordinate calculations to the vertex shader. If a calculation would have the same result across your image, or would linearly vary across it, look at moving that calculation into the vertex shader. Vertex shaders run once per vertex, whereas fragment shaders execute once per pixel, so a calculation performed in the former will run fewer times.
\f1 \'be\'a1\'c1\'bf\'b0\'d1\'b9\'a4\'d7\'f7\'d2\'c6\'b5\'bd\'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7\'a1\'a3\'b6\'a5\'b5\'e3\'d7\'c5\'c9\'ab\'c6\'f7\'b6\'d4\'c3\'bf\'b8\'f6\'b6\'a5\'b5\'e3\'d6\'b4\'d0\'d0\'d2\'bb\'b4\'ce\'a3\'ac\'c6\'ac\'b6\'ce\'d7\'c5\'c9\'ab\'c6\'f7\'b6\'d4\'c3\'bf\'b8\'f6\'cf\'f1\'cb\'d8\'d6\'b4\'d0\'d0\'d2\'bb\'b4\'ce\'a1\'a3
\f0 \
\ls7\ilvl0
\b \kerning1\expnd0\expndtw0 		\expnd0\expndtw0\kerning0
Use appropriate precision on mobile devices.
\b0 \'a0On certain mobile devices, it can be much faster to work with lower precision values in vectors. The addition of two\'a0
\f2\fs36 \cf11 \cb12 lowp vec4
\f0\fs40 \cf6 \cb1 s can often be done in a single clock cycle on these devices, where the addition of two\'a0
\f2\fs36 \cf11 \cb12 highp vec4
\f0\fs40 \cf6 \cb1 s can take four clock cycles. This is less important on desktop GPUs and more recent mobile GPUs, though, as they don\'92t have the same optimizations for low precision values.
\f1 \'d4\'da\'d2\'c6\'b6\'af\'c9\'e8\'b1\'b8\'c9\'cf\'ca\'b9\'d3\'c3\'ca\'ca\'b5\'b1\'b5\'c4\'be\'ab\'b6\'c8\'a1\'a3\'b5\'ab\'ca\'c7\'bd\'fc\'c6\'da\'b5\'c4\'d2\'c6\'b6\'af\'c9\'e8\'b1\'b8\'ba\'cd\'cb\'f9\'d3\'d0\'b5\'c4\'d7\'c0\'c3\'e6\'c9\'e8\'b1\'b8\'c3\'bb\'d3\'d0\'d5\'e2\'b8\'f6\'d0\'e8\'c7\'f3\'a3\'ac\'d2\'f2\'ce\'aa\'c3\'bb\'d3\'d0\'d7\'f6\'d5\'e2\'b7\'bd\'c3\'e6\'b5\'c4\'d3\'c5\'bb\'af
\f0 \
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl820\partightenfactor0

\b\fs69\fsmilli34560 \cf6 Conclusions and Resources\
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0

\b0\fs40 \cf6 Shaders seem kind of scary at first, but they are nothing more than modified C programs. Everything involved in creating a shader is stuff that most of us have dealt with at one point or another, just in a different context.\
One thing I would highly recommend for anyone trying to get into shaders is to refamiliarize yourself with trigonometry and linear algebra. The biggest stumbling block I encountered when working with this was that I didn\'92t remember a lot of the math I learned in high school, because I hadn\'92t used it in a really long time.\
There are some books I would recommend if your math is a little rusty:\
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl580\partightenfactor0
\ls8\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "http://www.amazon.com/Math-Primer-Graphics-Game-Development/dp/1568817231/ref=sr_1_1?ie=UTF8&qid=1422837187&sr=8-1&keywords=3d+math+primer+for+graphics+and+game+development"}}{\fldrslt \expnd0\expndtw0\kerning0
3D Math Primer for Graphics and Game Development}}\cf6 \expnd0\expndtw0\kerning0
\
\ls8\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "http://natureofcode.com/"}}{\fldrslt \expnd0\expndtw0\kerning0
The Nature of Code}}\cf6 \expnd0\expndtw0\kerning0
\
\ls8\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "http://www.amazon.com/Computational-Beauty-Nature-Explorations-Adaptation/dp/0262561271/ref=sr_1_1?s=books&ie=UTF8&qid=1422837256&sr=1-1&keywords=computational+beauty+of+nature"}}{\fldrslt \expnd0\expndtw0\kerning0
The Computational Beauty of Nature}}\cf6 \expnd0\expndtw0\kerning0
\
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 There are also countless books out there about GLSL and how some very specific shaders were created by prominent members of our industry:\
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl580\partightenfactor0
\ls9\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "http://www.amazon.com/Graphics-Shaders-Theory-Practice-Second/dp/1568814348/ref=sr_1_1?s=books&ie=UTF8&qid=1422837351&sr=1-1&keywords=graphics+shaders+theory+and+practice"}}{\fldrslt \expnd0\expndtw0\kerning0
Graphics Shaders: Theory and Practice}}\cf6 \expnd0\expndtw0\kerning0
\
\ls9\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "http://www.amazon.com/OpenGL-Shading-Language-Randi-Rost/dp/0321637631/ref=sr_1_1?s=books&ie=UTF8&qid=1422896457&sr=1-1&keywords=opengl+shading+language"}}{\fldrslt \expnd0\expndtw0\kerning0
The OpenGL Shading Language}}\cf6 \expnd0\expndtw0\kerning0
\
\ls9\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "http://www.amazon.com/OpenGL-Shading-Language-Cookbook-Second/dp/1782167021/ref=sr_1_2?s=books&ie=UTF8&qid=1422896457&sr=1-2&keywords=opengl+shading+language"}}{\fldrslt \expnd0\expndtw0\kerning0
OpenGL 4 Shading Language Cookbook}}\cf6 \expnd0\expndtw0\kerning0
\
\ls9\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "http://http.developer.nvidia.com/GPUGems/gpugems_part01.html"}}{\fldrslt \expnd0\expndtw0\kerning0
GPU Gems}}\cf6 \expnd0\expndtw0\kerning0
\
\ls9\ilvl0\cf7 \kerning1\expnd0\expndtw0 		{\field{\*\fldinst{HYPERLINK "http://www.amazon.com/GPU-Pro-Advanced-Rendering-Techniques/dp/1568814720/ref=sr_1_4?s=books&ie=UTF8&qid=1422837427&sr=1-4&keywords=gpu+pro"}}{\fldrslt \expnd0\expndtw0\kerning0
GPU Pro: Advanced Rendering Techniques}}\cf6 \expnd0\expndtw0\kerning0
\
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl600\partightenfactor0
\cf6 Also, again,\'a0{\field{\*\fldinst{HYPERLINK "https://github.com/BradLarson/GPUImage"}}{\fldrslt \cf7 GPUImage}}\'a0is an open-source resource to get a look at some really cool shaders. One good way to learn about shaders is to take a shader you find interesting and go through it line by line, looking up any part of it that you don\'92t understand. GPUImage also has a\'a0{\field{\*\fldinst{HYPERLINK "https://github.com/BradLarson/GPUImage/tree/master/examples/Mac/ShaderDesigner"}}{\fldrslt \cf7 shader designer}}\'a0application on the Mac side that lets you test out shaders without having to set up the OpenGL code.\
Learning how to effectively implement shaders in your code can give you a huge performance boost. Not only that, but shaders also allow you to do things that were not possible before.\
Learning shaders takes some tenacity and some curiosity, but they aren\'92t impossible. If a 33-year-old recovering journalism major could confront her math fear to tackle shaders, so can you.\
\pard\intbl\itap1\pardeftab720\li600\fi-14\ri-9798\sl360\sa663\partightenfactor0

\b\fs32 \cf15 CONTINUE READING ISSUE 21 
\b0\fs33\fsmilli16667 \cf16 \kerning1\expnd0\expndtw0 	 
\fs40 \cf5 \expnd0\expndtw0\kerning0
\cell \lastrow\row
}